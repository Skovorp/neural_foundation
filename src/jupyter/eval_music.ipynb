{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.join(os.getcwd(), '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/jk8j2nn905v4_76cbzdgkrxm0000gn/T/ipykernel_24147/711149925.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  encoder_sd = torch.load('/Users/ksc/Desktop/Нейротемка/checkpoints_70ep/encoder_2024-12-23T19:57:53.101820.pt', map_location=torch.device('cpu') )\n",
      "/var/folders/z2/jk8j2nn905v4_76cbzdgkrxm0000gn/T/ipykernel_24147/711149925.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  context_network_sd = torch.load('/Users/ksc/Desktop/Нейротемка/checkpoints_70ep/context_network_2024-12-23T19:57:53.101820.pt', map_location=torch.device('cpu') )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ContextNetwork(\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-19): 20 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (target_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (positional_emb): SinusoidalPositionalEncoding(\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from models.bendr import EncoderConv, ContextNetwork\n",
    "\n",
    "with open('configs/od_config_bendr.yaml', 'r') as file:\n",
    "        cfg = yaml.safe_load(file)\n",
    "\n",
    "\n",
    "encoder_sd = torch.load('/Users/ksc/Desktop/Нейротемка/checkpoints_70ep/encoder_2024-12-23T19:57:53.101820.pt', map_location=torch.device('cpu') )\n",
    "context_network_sd = torch.load('/Users/ksc/Desktop/Нейротемка/checkpoints_70ep/context_network_2024-12-23T19:57:53.101820.pt', map_location=torch.device('cpu') )\n",
    "\n",
    "\n",
    "encoder = EncoderConv(**cfg['encoder'])\n",
    "context_network = ContextNetwork(**cfg['context_network'])\n",
    "\n",
    "encoder.load_state_dict(encoder_sd)\n",
    "context_network.load_state_dict(context_network_sd)\n",
    "encoder.eval()\n",
    "context_network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One chunk from each file:  29%|██▊       | 2/7 [00:00<00:01,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping last 25752\n",
      "Skipping last 67992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One chunk from each file:  43%|████▎     | 3/7 [00:00<00:01,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping last 42936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One chunk from each file:  57%|█████▋    | 4/7 [00:01<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping last 61976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One chunk from each file:  86%|████████▌ | 6/7 [00:01<00:00,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping last 25784\n",
      "Skipping last 25176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One chunk from each file: 100%|██████████| 7/7 [00:01<00:00,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping last 12760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dataset.labeled_dataset import EEGLabeledDataset\n",
    "\n",
    "dataset = EEGLabeledDataset(\n",
    "    data_path='/Users/ksc/Desktop/Нейротемка/music_data/h5',\n",
    "    cache_processed_path='/Users/ksc/Desktop/Нейротемка/music_data/cache',\n",
    "    train_length=73728,\n",
    "    dataset_mode='sequential',\n",
    "    target_config={\n",
    "        'user_id': True,\n",
    "        'activity': True\n",
    "    },\n",
    "    clipped_threshold=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 73728])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(dataset, 2, shuffle=False, drop_last=False)\n",
    "next(iter(loader))['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': tensor([[[ 3.5227e-01,  3.0602e-01,  1.8820e-01,  ..., -1.8532e-01,\n",
       "           -2.8521e-02,  1.1881e-01],\n",
       "          [ 3.1634e-02,  3.5276e-02,  3.5589e-02,  ..., -1.7402e-01,\n",
       "           -2.6424e-01, -2.0152e-01],\n",
       "          [-1.2210e-01, -1.5446e-01, -1.4964e-01,  ..., -3.4669e-01,\n",
       "           -2.8352e-01, -9.2478e-03],\n",
       "          [ 2.0820e-01,  1.6746e-01,  6.9722e-02,  ..., -1.3563e-01,\n",
       "           -2.1028e-01, -1.7068e-01]],\n",
       " \n",
       "         [[ 1.7509e-01,  1.7674e-01,  2.4764e-01,  ...,  7.0802e-01,\n",
       "            5.3452e-01,  3.0425e-01],\n",
       "          [-9.0456e-02, -4.9613e-04,  3.0961e-02,  ...,  2.4119e-01,\n",
       "            1.5493e-01,  5.2908e-02],\n",
       "          [ 2.9720e-01,  5.0397e-01,  6.1361e-01,  ...,  2.9314e-01,\n",
       "            3.1932e-01,  3.4552e-01],\n",
       "          [-7.6991e-02,  2.6323e-02,  1.0559e-01,  ...,  5.6445e-01,\n",
       "            5.8005e-01,  5.1308e-01]]]),\n",
       " 'is_liked': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 2, 2, 2]]),\n",
       " 'song_ids': tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ..., 15, 15, 15]]),\n",
       " 'user_id': tensor([0, 0]),\n",
       " 'ind': tensor([0, 1]),\n",
       " 'encoder_features': tensor([[[-0.1675,  0.1142, -0.1690,  ..., -0.1317, -0.0529,  0.6576],\n",
       "          [-0.0814,  0.6108, -0.0311,  ..., -0.1172,  1.5519,  0.7606],\n",
       "          [ 0.0736, -0.1608,  0.7553,  ..., -0.0821,  0.2171,  0.5945],\n",
       "          ...,\n",
       "          [-0.1314, -0.1191, -0.1690,  ..., -0.1104, -0.0423,  0.6377],\n",
       "          [-0.1476, -0.0422, -0.1684,  ..., -0.1061,  0.4751,  0.9101],\n",
       "          [-0.0259, -0.1105,  0.0911,  ...,  0.0365, -0.0848,  0.8880]],\n",
       " \n",
       "         [[-0.1460, -0.1001, -0.1162,  ..., -0.1660,  2.1145,  1.0617],\n",
       "          [-0.1692, -0.1378,  0.0036,  ..., -0.1321, -0.0077, -0.1161],\n",
       "          [-0.0684,  0.2604, -0.1568,  ..., -0.0547, -0.0904,  0.7747],\n",
       "          ...,\n",
       "          [-0.1638,  0.1455, -0.1624,  ..., -0.1029, -0.0105,  0.2154],\n",
       "          [-0.1505,  0.3478, -0.1586,  ..., -0.0588,  1.9080, -0.1699],\n",
       "          [-0.0612, -0.0877, -0.0992,  ..., -0.0598,  1.2268,  0.6040]]],\n",
       "        grad_fn=<PermuteBackward0>),\n",
       " 'full_context_vectors': tensor([[[ 1.2847e+02,  3.4829e-01,  4.5183e+01,  ..., -2.6134e+01,\n",
       "           -5.5697e+00,  1.6874e+01],\n",
       "          [ 2.2014e+02, -7.1337e-01,  5.6823e+01,  ..., -3.0040e+01,\n",
       "           -9.9020e+00,  2.8391e+01],\n",
       "          [ 4.0235e+02, -7.3556e+00,  6.3364e+01,  ..., -3.1491e+01,\n",
       "           -1.2172e+01,  4.5576e+01],\n",
       "          ...,\n",
       "          [ 4.1492e+02, -2.0329e+01,  7.0819e+01,  ..., -5.3521e+00,\n",
       "            1.5394e+01,  7.9704e+01],\n",
       "          [ 2.9785e+02, -2.1637e+01,  5.6743e+01,  ..., -5.7766e+00,\n",
       "            1.4130e+01,  7.9833e+01],\n",
       "          [ 2.7035e+02, -1.9173e+01,  5.3543e+01,  ..., -3.8677e+00,\n",
       "            1.4021e+01,  8.1301e+01]],\n",
       " \n",
       "         [[ 4.9542e+02,  8.4168e+00,  4.3350e+01,  ...,  1.0126e+01,\n",
       "            2.7199e+01,  7.1390e+00],\n",
       "          [ 3.4973e+02,  1.7285e+01,  4.4621e+01,  ...,  9.2707e+00,\n",
       "            2.6150e+01, -1.8024e+01],\n",
       "          [ 2.1232e+02, -4.6936e+01,  4.4211e+01,  ..., -2.1920e+01,\n",
       "            1.3006e+01, -5.5823e+01],\n",
       "          ...,\n",
       "          [ 3.9328e+02, -1.0281e+01,  5.4183e+01,  ..., -3.4139e+01,\n",
       "           -1.3087e+01,  5.3505e+01],\n",
       "          [ 2.4955e+02, -7.9392e+00,  4.4625e+01,  ..., -2.5274e+01,\n",
       "           -1.0796e+01,  4.4070e+01],\n",
       "          [ 2.6493e+02, -6.9107e+00,  4.6319e+01,  ..., -2.2427e+01,\n",
       "           -1.0019e+01,  4.5308e+01]]], grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device('cuda')\n",
    "# encoder = encoder.to(device)\n",
    "# context_network = context_network.to(device)\n",
    "\n",
    "batch = next(iter(loader))\n",
    "batch['data'] = batch['data'] #].to(device)\n",
    "batch = encoder(batch)\n",
    "batch = context_network(batch, run_full=True)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:23<00:00,  1.04it/s]\n"
     ]
    }
   ],
   "source": [
    "context = []\n",
    "uid = []\n",
    "song_id = []\n",
    "is_liked = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(loader):\n",
    "        batch = encoder(batch)\n",
    "        batch = context_network(batch, run_full=True)\n",
    "        context.append(batch['full_context_vectors'])\n",
    "        uid.append(batch['user_id'])\n",
    "        song_id.append(batch['song_ids'])\n",
    "        is_liked.append(batch['is_liked'])\n",
    "\n",
    "context = torch.cat(context, 0)\n",
    "uid = torch.cat(uid, 0)\n",
    "song_id = torch.cat(song_id, 0)\n",
    "is_liked = torch.cat(is_liked, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([47, 768, 512])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6]\n",
    "# [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_test = [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([47, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_liked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_per_item = uid.view(1, -1).repeat(768, 1).T.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', '.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid_per_item.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36096])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_id.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_per_item = uid.view(1, -1).repeat(768, 1).T.flatten()\n",
    "song_per_item = song_id.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36096])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_per_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "        37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = song_per_item[uid_per_item == 4]\n",
    "a.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.25"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "53 /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9194625419864708\n",
      "1 0.9828882337639817\n",
      "2 0.9528329886076365\n",
      "3 0.908150293150293\n",
      "4 0.9342981186685962\n",
      "5 0.9235962436908887\n",
      "6 0.9254078083138882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from eval.reg import evaluate_logistic_regression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', '.*')\n",
    "\n",
    "results = []\n",
    "\n",
    "uid_per_item = uid.view(1, -1).repeat(768, 1).T.flatten()\n",
    "song_per_item = song_id.flatten()\n",
    "\n",
    "X = context.view(47 * 768, 512)\n",
    "y = is_liked.view(47 * 768)\n",
    "for user in range(7):\n",
    "    my_x = X[uid_per_item == user]\n",
    "    my_y = y[uid_per_item == user]\n",
    "    my_songs = song_per_item[uid_per_item == user]\n",
    "    \n",
    "    not_zero = (my_y != 0)\n",
    "    my_x = my_x[not_zero]\n",
    "    my_y = my_y[not_zero]\n",
    "    # my_songs = my_songs[not_zero]\n",
    "    \n",
    "    \n",
    "    # for song in my_songs.unique():\n",
    "    #     my_x[my_songs == song].mean(0)\n",
    "    \n",
    "    results.append(evaluate_logistic_regression(my_x, my_y, 'cv', do_norm=False))\n",
    "    \n",
    "for i in range(len(results)):\n",
    "    print(i, results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9194625419864708\n",
      "1 0.9828882337639817\n",
      "2 0.9528329886076365\n",
      "3 0.908150293150293\n",
      "4 0.9342981186685962\n",
      "5 0.9235962436908887\n",
      "6 0.9254078083138882\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(results)):\n",
    "    print(i, results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def evaluate_logistic_regression_2(X, y, mode, do_norm):\n",
    "    if do_norm:\n",
    "        X = X / torch.norm(X, dim=1, keepdim=True)\n",
    "    X, y = X.numpy(), y.numpy()\n",
    "    prm = np.random.permutation(y.shape[0])\n",
    "    X, y = X[prm, :], y[prm]\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    if mode == \"self\":\n",
    "        model.fit(X, y)\n",
    "        y_pred = model.predict(X)\n",
    "        return accuracy_score(y, y_pred)\n",
    "    elif mode == 'cv':\n",
    "        accuracies = cross_val_score(model, X, y, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        return np.mean(accuracies)\n",
    "    else:\n",
    "        assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0\n",
      "1 1.0\n",
      "2 1.0\n",
      "3 1.0\n",
      "4 1.0\n",
      "5 1.0\n",
      "6 1.0\n"
     ]
    }
   ],
   "source": [
    "from eval.reg import evaluate_logistic_regression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', '.*')\n",
    "\n",
    "results = []\n",
    "\n",
    "uid_per_item = uid.view(1, -1).repeat(768, 1).T.flatten()\n",
    "song_per_item = song_id.flatten()\n",
    "\n",
    "X = context.view(47 * 768, 512)\n",
    "y = is_liked.view(47 * 768)\n",
    "for user in range(7):\n",
    "    my_x = X[uid_per_item == user]\n",
    "    my_y = y[uid_per_item == user]\n",
    "    my_songs = song_per_item[uid_per_item == user]\n",
    "    \n",
    "    not_zero = (my_y != 0)\n",
    "    my_x = my_x[not_zero]\n",
    "    my_y = my_y[not_zero]\n",
    "    my_songs = my_songs[not_zero]\n",
    "    \n",
    "    agg_x = []\n",
    "    agg_y = []\n",
    "    for song in my_songs.unique():\n",
    "        agg_x.append(torch.cat([\n",
    "           my_x[my_songs == song].mean(0),\n",
    "           my_x[my_songs == song].min(0).values,\n",
    "           my_x[my_songs == song].max(0).values \n",
    "        ]))\n",
    "        new_y = my_y[my_songs == song]\n",
    "        assert new_y.min() == new_y.max()\n",
    "        agg_y.append(new_y[0])\n",
    "        \n",
    "    agg_x = torch.stack(agg_x)\n",
    "    agg_y = torch.tensor(agg_y)\n",
    "    \n",
    "    # results.append(\n",
    "    print(user, evaluate_logistic_regression_2(agg_x, agg_y, 'self', do_norm=False))\n",
    "    \n",
    "    # OVERFIT!\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.reg import evaluate_logistic_regression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', '.*')\n",
    "\n",
    "results = []\n",
    "\n",
    "uid_per_item = uid.view(1, -1).repeat(768, 1).T.flatten()\n",
    "song_per_item = song_id.flatten()\n",
    "\n",
    "X = context.view(47 * 768, 512)\n",
    "y = is_liked.view(47 * 768)\n",
    "\n",
    "# TRAIN/TEST по невиденным до этого песням!\n",
    "\n",
    "for user in range(7):\n",
    "    my_x = X[uid_per_item == user]\n",
    "    my_y = y[uid_per_item == user]\n",
    "    my_songs = song_per_item[uid_per_item == user]\n",
    "    \n",
    "    not_zero = (my_y != 0)\n",
    "    my_x = my_x[not_zero]\n",
    "    my_y = my_y[not_zero]\n",
    "    my_songs = my_songs[not_zero]\n",
    "    \n",
    "    agg_x = []\n",
    "    agg_y = []\n",
    "    for song in my_songs.unique():\n",
    "        agg_x.append(torch.cat([\n",
    "           my_x[my_songs == song].mean(0),\n",
    "           my_x[my_songs == song].min(0).values,\n",
    "           my_x[my_songs == song].max(0).values \n",
    "        ]))\n",
    "        new_y = my_y[my_songs == song]\n",
    "        assert new_y.min() == new_y.max()\n",
    "        agg_y.append(new_y[0])\n",
    "        \n",
    "    agg_x = torch.stack(agg_x)\n",
    "    agg_y = torch.tensor(agg_y)\n",
    "    \n",
    "    # results.append(\n",
    "    print(user, evaluate_logistic_regression_2(agg_x, agg_y, 'cv', do_norm=False))\n",
    "    \n",
    "    # OVERFIT!\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7616425988822091"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(47, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaner eval\n",
    "\n",
    "for each person, last halve of songs - eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_id * 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([350, 512]) torch.Size([170, 512])\n",
      "User 0: Train Accuracy = 0.7143\n",
      "User 0: Test Accuracy = 0.4706\n",
      "torch.Size([350, 512]) torch.Size([90, 512])\n",
      "User 1: Train Accuracy = 0.8571\n",
      "User 1: Test Accuracy = 0.6667\n",
      "torch.Size([350, 512]) torch.Size([140, 512])\n",
      "User 2: Train Accuracy = 0.6857\n",
      "User 2: Test Accuracy = 0.9286\n",
      "torch.Size([350, 512]) torch.Size([110, 512])\n",
      "User 3: Train Accuracy = 0.6857\n",
      "User 3: Test Accuracy = 0.5455\n",
      "torch.Size([350, 512]) torch.Size([150, 512])\n",
      "User 4: Train Accuracy = 0.4857\n",
      "User 4: Test Accuracy = 0.7333\n",
      "torch.Size([350, 512]) torch.Size([150, 512])\n",
      "User 5: Train Accuracy = 0.7429\n",
      "User 5: Test Accuracy = 0.6667\n",
      "torch.Size([350, 512]) torch.Size([167, 512])\n",
      "User 6: Train Accuracy = 0.6857\n",
      "User 6: Test Accuracy = 0.3593\n",
      "FINAL: tensor(0.6141)\n"
     ]
    }
   ],
   "source": [
    "from eval.reg import evaluate_logistic_regression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', '.*')\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "results = []\n",
    "\n",
    "uid_per_item = (uid.view(-1, 1) + song_id * 0).flatten() # uid.view(1, -1).repeat(768, 1).T.flatten()\n",
    "song_per_item = song_id.flatten()\n",
    "\n",
    "X = context.view(47 * 768, 512)\n",
    "y = is_liked.view(47 * 768)\n",
    "\n",
    "r = []\n",
    "\n",
    "for user in range(7):\n",
    "    my_x = X[uid_per_item == user]\n",
    "    my_y = y[uid_per_item == user]\n",
    "    my_songs = song_per_item[uid_per_item == user]  # uid_per_item == user]\n",
    "    \n",
    "    not_zero = (my_y != 0)\n",
    "    my_x = my_x[not_zero]\n",
    "    my_y = my_y[not_zero]\n",
    "    my_songs = my_songs[not_zero]\n",
    "    \n",
    "    edge = ind_from_edge(my_songs)\n",
    "    # print(edge)\n",
    "    my_x = my_x[edge <= 10]\n",
    "    my_y = my_y[edge <= 10]\n",
    "    my_songs = my_songs[edge <= 10]\n",
    "    \n",
    "    songs_seq = torch.unique_consecutive(my_songs).numpy()\n",
    "    # np.random.shuffle(songs_seq)\n",
    "    \n",
    "    train_songs = songs_seq[:35]\n",
    "    train_mask = np.isin(my_songs.numpy(), train_songs)\n",
    "    \n",
    "    # np.random.shuffle(train_mask) -- this causes score boost from 0.5/0.7 to 0.9\n",
    "\n",
    "    \n",
    "    train_x = my_x[train_mask]\n",
    "    train_y = my_y[train_mask]\n",
    "    test_x = my_x[~train_mask]\n",
    "    test_y = my_y[~train_mask]\n",
    "    \n",
    "    print(train_x.shape, test_x.shape)\n",
    "    \n",
    "    # Train logistic regression model\n",
    "    model = LogisticRegression(penalty='l1', solver='liblinear', C=0.0001) # LogisticRegression(max_iter=2000)\n",
    "    model.fit(train_x, train_y)\n",
    "    \n",
    "    # Predict and calculate accuracy on train and test sets\n",
    "    train_predictions = model.predict(train_x)\n",
    "    train_accuracy = accuracy_score(train_y, train_predictions)\n",
    "    print(f\"User {user}: Train Accuracy = {train_accuracy:.4f}\")\n",
    "    \n",
    "    test_predictions = model.predict(test_x)\n",
    "    test_accuracy = accuracy_score(test_y, test_predictions)\n",
    "    r.append(test_y == test_predictions)\n",
    "    print(f\"User {user}: Test Accuracy = {test_accuracy:.4f}\")\n",
    "print(\"FINAL:\", (torch.cat(r) * 1.0).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6018)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.cat(r) * 1.0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ind_from_edge(data):\n",
    "    # numbers = [0] * len(data)\n",
    "\n",
    "    # # Step 2: Group indices of identical elements\n",
    "    # unique_values = set(data)\n",
    "    # for value in unique_values:\n",
    "    #     # Find indices of current value in the data array\n",
    "    #     indices = [i for i, v in enumerate(data) if v == value]\n",
    "    #     # Assign numbers starting from 1 at the rightmost element\n",
    "    #     for rank, idx in enumerate(reversed(indices), start=1):\n",
    "    #         numbers[idx] = rank\n",
    "    numbers = torch.zeros_like(data)\n",
    "\n",
    "    # Find unique values and their inverse indices\n",
    "    unique_values, inverse_indices = torch.unique(data, return_inverse=True)\n",
    "\n",
    "    # Iterate over unique values to assign numbers\n",
    "    for value in unique_values:\n",
    "        # Get indices where data matches the current value\n",
    "        indices = (data == value).nonzero(as_tuple=True)[0]\n",
    "        # Assign ranks in reverse order\n",
    "        numbers[indices] = torch.arange(len(indices), 0, -1)\n",
    "            \n",
    "    return numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([62, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45,\n",
       "        44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27,\n",
       "        26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10,  9,\n",
       "         8,  7,  6,  5,  4,  3,  2,  1, 63, 62, 61, 60, 59, 58, 57, 56])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_from_edge(my_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
       "        34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
       "        34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
       "        34, 34, 34, 34, 34, 34, 34, 34, 45, 45, 45, 45, 45, 45, 45, 45])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_songs[:70]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
