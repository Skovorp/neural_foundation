{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math \n",
    "import torch.nn.functional as F\n",
    "\n",
    "batch = {\n",
    "    'targets': torch.randn(2, 8, 64),\n",
    "    'context_vectors': torch.randn(2, 8, 64),\n",
    "    'mask': torch.tensor([[True, True, False, False, False, True, False, True], [True, True, False, False, False, True, False, True]]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_targets.shape torch.Size([2, 4, 10, 64])\n",
      "sims.shape torch.Size([2, 4, 10])\n",
      "sims.shape torch.Size([2, 10, 4])\n",
      "tensor([[[ 0.1281,  0.0933,  0.0367,  0.0962],\n",
      "         [-0.0189, -0.1945, -0.1550,  0.1376],\n",
      "         [-0.0189, -0.1945,  0.1209,  0.1142],\n",
      "         [-0.1352, -0.1945, -0.1550,  0.1142],\n",
      "         [-0.0189, -0.1945, -0.1550, -0.0005],\n",
      "         [ 0.0146, -0.1945,  0.1209, -0.0005],\n",
      "         [-0.1352,  0.1060, -0.1550,  0.1142],\n",
      "         [-0.1352,  0.1060, -0.1386,  0.1376],\n",
      "         [-0.1352, -0.0711, -0.1386, -0.0005],\n",
      "         [ 0.0146,  0.1060, -0.1550,  0.1376]],\n",
      "\n",
      "        [[ 0.1714, -0.0463,  0.1032, -0.0398],\n",
      "         [ 0.0543,  0.0474, -0.2090, -0.1568],\n",
      "         [ 0.0316, -0.0538, -0.2090, -0.0862],\n",
      "         [ 0.0316, -0.0538, -0.1191, -0.1568],\n",
      "         [ 0.0543, -0.0356, -0.2090,  0.2554],\n",
      "         [ 0.0543, -0.0356,  0.2331, -0.1568],\n",
      "         [ 0.0316, -0.0356,  0.2331, -0.1568],\n",
      "         [ 0.0316,  0.0474, -0.2090, -0.1568],\n",
      "         [ 0.0316, -0.0356,  0.2331, -0.0862],\n",
      "         [ 0.0316, -0.0356,  0.2331, -0.1568]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.2222)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "calc_loss_proper(batch, 1, 9)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_tokens, emb_size = batch['targets'].shape\n",
    "\n",
    "torch.count_nonzero(x, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d= torch.tensor([\n",
    "    [1, 2, 1, 0, 1, 0],\n",
    "    [1, 0, 0, 0, 1, 2],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nz = torch.count_nonzero(d > 0, dim=1)\n",
    "nz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([85, 85, 85, 85, 85, 85, 85, 85, 85, 85])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_pretrain_mask(batch_size, num_chunks, mask_prob, mask_length):\n",
    "    mask = 1 * (torch.rand(batch_size, num_chunks) < mask_prob)\n",
    "        \n",
    "    mask[:, mask_length:] = mask[:, mask_length:] - mask[:, : -mask_length]\n",
    "    mask = mask.cumsum(1) > 0\n",
    "    \n",
    "    non_zero = torch.count_nonzero(mask, dim=1)\n",
    "    set_extra_ones = non_zero.max() - non_zero\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        j = 0\n",
    "        while set_extra_ones[i] > 0:\n",
    "            if not mask[i, j]:\n",
    "                mask[i, j] = True\n",
    "                set_extra_ones[i] -= 1\n",
    "            j += 1\n",
    "    \n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [0, 1],\n",
       "        [0, 2],\n",
       "        [0, 4],\n",
       "        [1, 0],\n",
       "        [1, 4],\n",
       "        [1, 5]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vectors = torch.rand(8, 16, 128)\n",
    "features = torch.rand(8, 16, 128)\n",
    "\n",
    "mask = make_pretrain_mask(8, 16, 0.3, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 11, 11, 11, 11, 11, 11, 11])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "        False, False,  True,  True, False,  True])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.4521e-01, 1.5442e-01, 1.3543e-01, 4.0935e-01, 2.9178e-01, 7.0763e-01,\n",
       "        6.3046e-01, 7.8960e-02, 1.7042e-01, 8.6654e-01, 5.2912e-01, 8.5400e-01,\n",
       "        9.7545e-02, 5.2555e-01, 8.8126e-01, 8.4989e-01, 9.7351e-01, 2.8159e-01,\n",
       "        7.0202e-01, 4.1599e-01, 7.1815e-01, 8.4082e-01, 4.0098e-01, 4.3547e-01,\n",
       "        9.3482e-01, 8.0287e-01, 1.2611e-01, 2.7833e-01, 9.8822e-01, 1.9635e-01,\n",
       "        3.0488e-02, 5.1590e-01, 4.2680e-01, 3.1658e-01, 3.9386e-01, 4.8499e-01,\n",
       "        7.8971e-02, 4.0638e-01, 8.4209e-01, 4.5078e-01, 6.0780e-01, 3.5798e-01,\n",
       "        8.9602e-01, 3.2764e-01, 9.6160e-01, 3.6570e-01, 5.1641e-01, 5.2647e-01,\n",
       "        1.7558e-01, 6.9024e-02, 8.7559e-01, 2.6599e-01, 3.6647e-01, 8.1979e-01,\n",
       "        5.3891e-01, 6.8915e-01, 1.5978e-01, 9.9805e-01, 2.8983e-01, 6.1333e-01,\n",
       "        2.1150e-01, 8.0969e-01, 8.4807e-01, 4.7146e-01, 9.1682e-01, 6.1308e-02,\n",
       "        3.7447e-01, 5.2176e-02, 4.1289e-01, 5.1539e-01, 5.5136e-01, 9.1067e-01,\n",
       "        1.1590e-01, 7.6090e-01, 9.6427e-01, 7.4946e-01, 1.2970e-04, 6.6660e-01,\n",
       "        7.3817e-02, 3.8015e-01, 1.5715e-01, 1.5889e-01, 8.2489e-01, 3.2897e-01,\n",
       "        2.4474e-01, 5.1002e-01, 7.9657e-01, 4.2598e-01, 9.3603e-01, 9.2867e-01,\n",
       "        9.1118e-02, 2.8243e-01, 5.0520e-01, 7.2199e-01, 6.7795e-02, 7.5339e-01,\n",
       "        7.9930e-02, 2.2943e-01, 1.3582e-01, 6.6726e-01, 7.0491e-01, 4.4931e-01,\n",
       "        8.2210e-01, 2.4506e-01, 3.6813e-01, 1.1041e-01, 1.1548e-01, 3.8659e-01,\n",
       "        5.0438e-01, 9.8299e-02, 9.5252e-01, 7.9185e-01, 3.0921e-01, 4.3170e-01,\n",
       "        5.3204e-01, 6.6421e-01, 4.7097e-01, 5.2685e-01, 4.4069e-01, 3.9766e-01,\n",
       "        6.1928e-01, 6.9723e-01, 2.2798e-01, 6.6161e-01, 7.6469e-01, 9.6985e-01,\n",
       "        7.1319e-01, 2.4188e-01])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_context = context_vectors[mask].view(context_vectors.size(0), -1, context_vectors.size(-1))\n",
    "masked_features = features[mask].view(features.size(0), -1, features.size(-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_negatives()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 1, 2, 1, 2])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1, 2], [1, 2], [1, 2]]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [1, 1, 1],\n",
       "        [2, 2, 2],\n",
       "        [3, 3, 3],\n",
       "        [4, 4, 4]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(5).unsqueeze(-1).expand(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(5).unsqueeze(-1).expand(-1, 3).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.rand(8, 11, 4, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[14, 14, 14, 14, 14, 14, 14, 14],\n",
       "         [13, 13, 13, 13, 13, 13, 13, 13],\n",
       "         [14, 14, 14, 14, 14, 14, 14, 14],\n",
       "         [15, 15, 15, 15, 15, 15, 15, 15],\n",
       "         [13, 13, 13, 13, 13, 13, 13, 13]],\n",
       "\n",
       "        [[14, 14, 14, 14, 14, 14, 14, 14],\n",
       "         [17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [18, 18, 18, 18, 18, 18, 18, 18],\n",
       "         [16, 16, 16, 16, 16, 16, 16, 16],\n",
       "         [10, 10, 10, 10, 10, 10, 10, 10]],\n",
       "\n",
       "        [[11, 11, 11, 11, 11, 11, 11, 11],\n",
       "         [11, 11, 11, 11, 11, 11, 11, 11],\n",
       "         [15, 15, 15, 15, 15, 15, 15, 15],\n",
       "         [14, 14, 14, 14, 14, 14, 14, 14],\n",
       "         [16, 16, 16, 16, 16, 16, 16, 16]],\n",
       "\n",
       "        [[12, 12, 12, 12, 12, 12, 12, 12],\n",
       "         [11, 11, 11, 11, 11, 11, 11, 11],\n",
       "         [14, 14, 14, 14, 14, 14, 14, 14],\n",
       "         [11, 11, 11, 11, 11, 11, 11, 11],\n",
       "         [12, 12, 12, 12, 12, 12, 12, 12]],\n",
       "\n",
       "        [[13, 13, 13, 13, 13, 13, 13, 13],\n",
       "         [11, 11, 11, 11, 11, 11, 11, 11],\n",
       "         [13, 13, 13, 13, 13, 13, 13, 13],\n",
       "         [11, 11, 11, 11, 11, 11, 11, 11],\n",
       "         [11, 11, 11, 11, 11, 11, 11, 11]],\n",
       "\n",
       "        [[17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [13, 13, 13, 13, 13, 13, 13, 13],\n",
       "         [14, 14, 14, 14, 14, 14, 14, 14],\n",
       "         [10, 10, 10, 10, 10, 10, 10, 10],\n",
       "         [16, 16, 16, 16, 16, 16, 16, 16]],\n",
       "\n",
       "        [[19, 19, 19, 19, 19, 19, 19, 19],\n",
       "         [15, 15, 15, 15, 15, 15, 15, 15],\n",
       "         [18, 18, 18, 18, 18, 18, 18, 18],\n",
       "         [14, 14, 14, 14, 14, 14, 14, 14],\n",
       "         [17, 17, 17, 17, 17, 17, 17, 17]],\n",
       "\n",
       "        [[12, 12, 12, 12, 12, 12, 12, 12],\n",
       "         [10, 10, 10, 10, 10, 10, 10, 10],\n",
       "         [13, 13, 13, 13, 13, 13, 13, 13],\n",
       "         [16, 16, 16, 16, 16, 16, 16, 16],\n",
       "         [15, 15, 15, 15, 15, 15, 15, 15]],\n",
       "\n",
       "        [[11, 11, 11, 11, 11, 11, 11, 11],\n",
       "         [11, 11, 11, 11, 11, 11, 11, 11],\n",
       "         [17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [13, 13, 13, 13, 13, 13, 13, 13],\n",
       "         [17, 17, 17, 17, 17, 17, 17, 17]],\n",
       "\n",
       "        [[16, 16, 16, 16, 16, 16, 16, 16],\n",
       "         [18, 18, 18, 18, 18, 18, 18, 18],\n",
       "         [16, 16, 16, 16, 16, 16, 16, 16],\n",
       "         [16, 16, 16, 16, 16, 16, 16, 16],\n",
       "         [18, 18, 18, 18, 18, 18, 18, 18]]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pick_negatives(x, num_negatives):\n",
    "    # for each el in seq_len get num_negatives other els from the same batch\n",
    "    batch_size, seq_len, emb_size = x.shape \n",
    "    \n",
    "    self_indexes = torch.arange(seq_len).unsqueeze(-1).expand(-1, num_negatives) # (seq_len, num_negatives)\n",
    "\n",
    "    neg_idxs = torch.randint(low=0, high=seq_len - 1, size=(batch_size, seq_len, num_negatives))\n",
    "                             \n",
    "    neg_idxs[neg_idxs >= self_indexes.unsqueeze(0)] += 1\n",
    "    neg_idxs = neg_idxs.view(batch_size, seq_len * num_negatives, 1).expand(batch_size, seq_len * num_negatives, emb_size)\n",
    "\n",
    "    res = torch.gather(x, 1, neg_idxs).view(batch_size, seq_len, num_negatives, emb_size)\n",
    "    return res\n",
    "\n",
    "    \n",
    "l = torch.arange(20).view(2, 10, 1).expand(2, 10, 8)\n",
    "r = pick_negatives(l, 5)\n",
    "r[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 50, 8])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 3, 3, 3, 3, 3, 3],\n",
       "        [8, 8, 8, 8, 8, 8, 8, 8],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [4, 4, 4, 4, 4, 4, 4, 4],\n",
       "        [4, 4, 4, 4, 4, 4, 4, 4]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0, 5, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13, 13, 13, 13, 13, 13, 13, 13])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1, 3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(torch.arange(10).view(2, 5), 1, torch.tensor([[0, 1], [0, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8, 11, 128 <- context\n",
    "8, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 11, 128])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 11])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cosine_similarity(masked_context, masked_features, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_tokens, emb_size = batch['targets'].shape\n",
    "targets, preds = batch['targets'], batch['context_vectors']\n",
    "norm_targets = torch.norm(targets, 2, dim=2, keepdim=True) # batch_size, num_tokens, 1\n",
    "norm_preds = torch.norm(preds, 2, dim=2, keepdim=True) # batch_size, num_tokens, 1\n",
    "\n",
    "good_targets = targets / norm_targets\n",
    "good_preds = preds / norm_preds\n",
    "\n",
    "# targets = torch.cat([targets, 100 * torch.ones(batch_size, 5, emb_size, device=batch['targets'].device)], dim=1)\n",
    "\n",
    "sim = good_preds @ good_targets.permute(0, 2, 1) # batch_size, num_tokens, num_tokens\n",
    "sim = sim[batch['mask']] # num_masked, num_tokens -- for every masked prediction, logits  per all seq\n",
    "labels = torch.tile(torch.arange(num_tokens), (batch_size, 1))\n",
    "labels = labels[batch['mask']].to(batch['targets'].device)\n",
    "sim = sim * math.exp(log_temp)\n",
    "unreduced_loss = F.cross_entropy(sim, labels, reduction='none')\n",
    "\n",
    "# set batch=1, num_chunks=8 to see how things works\n",
    "print(sim[:batch['mask'][0].sum()])\n",
    "print(batch['mask'][0])\n",
    "print(labels[:batch['mask'][0].sum()])\n",
    "print(F.cross_entropy(sim, labels, reduction='none'))\n",
    "# example of good vals\n",
    "# tensor([[ 2.7511, -0.5308, -0.3625, -0.2960, -0.2756, -0.3741, -0.3812, -0.5015],\n",
    "#     [-0.6111,  2.7569, -0.2216, -0.6170, -0.3746, -0.5203, -0.1013, -0.3689],\n",
    "#     [-0.1247, -0.1079, -0.2098, -0.2186,  2.7137, -0.1079, -0.1882, -0.3002],\n",
    "#     [-0.0668, -0.6090, -0.4044, -0.5796, -0.3214,  2.5963, -0.1835, -0.6229],\n",
    "#     [-0.3907, -0.5906, -0.5988, -0.4737, -0.7476, -0.6327,  2.7852, -0.6409],\n",
    "#     [-0.3811, -0.4140, -0.5004, -0.3402, -0.3983, -0.5376, -0.3075,  2.6888]],\n",
    "#    device='cuda:0', grad_fn=<MulBackward0>)\n",
    "# tensor([[ True,  True, False, False,  True,  True,  True,  True]])\n",
    "# tensor([0, 1, 4, 5, 6, 7], device='cuda:0')\n",
    "# loss: 0.27600 -- close to orthogonal optimum\n",
    "\n",
    "batch['per_masktoken_loss'] = unreduced_loss\n",
    "batch['loss'] = unreduced_loss.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
